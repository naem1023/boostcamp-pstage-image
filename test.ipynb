{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18().cuda()\n",
    "\n",
    "import timm\n",
    "mv2 = timm.create_model('mobilenetv2_100').cuda()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(resnet18, input_size=(3,244,244))\n",
    "summary(mv2, input_size=(3,244,244))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 122, 122]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 122, 122]             128\n",
      "              ReLU-3         [-1, 64, 122, 122]               0\n",
      "         MaxPool2d-4           [-1, 64, 61, 61]               0\n",
      "            Conv2d-5           [-1, 64, 61, 61]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 61, 61]             128\n",
      "              ReLU-7           [-1, 64, 61, 61]               0\n",
      "            Conv2d-8           [-1, 64, 61, 61]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 61, 61]             128\n",
      "             ReLU-10           [-1, 64, 61, 61]               0\n",
      "       BasicBlock-11           [-1, 64, 61, 61]               0\n",
      "           Conv2d-12           [-1, 64, 61, 61]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 61, 61]             128\n",
      "             ReLU-14           [-1, 64, 61, 61]               0\n",
      "           Conv2d-15           [-1, 64, 61, 61]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 61, 61]             128\n",
      "             ReLU-17           [-1, 64, 61, 61]               0\n",
      "       BasicBlock-18           [-1, 64, 61, 61]               0\n",
      "           Conv2d-19          [-1, 128, 31, 31]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 31, 31]             256\n",
      "             ReLU-21          [-1, 128, 31, 31]               0\n",
      "           Conv2d-22          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 31, 31]             256\n",
      "           Conv2d-24          [-1, 128, 31, 31]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 31, 31]             256\n",
      "             ReLU-26          [-1, 128, 31, 31]               0\n",
      "       BasicBlock-27          [-1, 128, 31, 31]               0\n",
      "           Conv2d-28          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 31, 31]             256\n",
      "             ReLU-30          [-1, 128, 31, 31]               0\n",
      "           Conv2d-31          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 31, 31]             256\n",
      "             ReLU-33          [-1, 128, 31, 31]               0\n",
      "       BasicBlock-34          [-1, 128, 31, 31]               0\n",
      "           Conv2d-35          [-1, 256, 16, 16]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 16, 16]             512\n",
      "             ReLU-37          [-1, 256, 16, 16]               0\n",
      "           Conv2d-38          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 16, 16]             512\n",
      "           Conv2d-40          [-1, 256, 16, 16]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 16, 16]             512\n",
      "             ReLU-42          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-43          [-1, 256, 16, 16]               0\n",
      "           Conv2d-44          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 16, 16]             512\n",
      "             ReLU-46          [-1, 256, 16, 16]               0\n",
      "           Conv2d-47          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 16, 16]             512\n",
      "             ReLU-49          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-50          [-1, 256, 16, 16]               0\n",
      "           Conv2d-51            [-1, 512, 8, 8]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-53            [-1, 512, 8, 8]               0\n",
      "           Conv2d-54            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-56            [-1, 512, 8, 8]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-58            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-59            [-1, 512, 8, 8]               0\n",
      "           Conv2d-60            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-62            [-1, 512, 8, 8]               0\n",
      "           Conv2d-63            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-65            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-66            [-1, 512, 8, 8]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.68\n",
      "Forward/backward pass size (MB): 76.08\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 121.36\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 122, 122]             864\n",
      "       BatchNorm2d-2         [-1, 32, 122, 122]              64\n",
      "             ReLU6-3         [-1, 32, 122, 122]               0\n",
      "            Conv2d-4         [-1, 32, 122, 122]             288\n",
      "       BatchNorm2d-5         [-1, 32, 122, 122]              64\n",
      "             ReLU6-6         [-1, 32, 122, 122]               0\n",
      "          Identity-7         [-1, 32, 122, 122]               0\n",
      "            Conv2d-8         [-1, 16, 122, 122]             512\n",
      "       BatchNorm2d-9         [-1, 16, 122, 122]              32\n",
      "         Identity-10         [-1, 16, 122, 122]               0\n",
      "DepthwiseSeparableConv-11         [-1, 16, 122, 122]               0\n",
      "           Conv2d-12         [-1, 96, 122, 122]           1,536\n",
      "      BatchNorm2d-13         [-1, 96, 122, 122]             192\n",
      "            ReLU6-14         [-1, 96, 122, 122]               0\n",
      "           Conv2d-15           [-1, 96, 61, 61]             864\n",
      "      BatchNorm2d-16           [-1, 96, 61, 61]             192\n",
      "            ReLU6-17           [-1, 96, 61, 61]               0\n",
      "         Identity-18           [-1, 96, 61, 61]               0\n",
      "           Conv2d-19           [-1, 24, 61, 61]           2,304\n",
      "      BatchNorm2d-20           [-1, 24, 61, 61]              48\n",
      " InvertedResidual-21           [-1, 24, 61, 61]               0\n",
      "           Conv2d-22          [-1, 144, 61, 61]           3,456\n",
      "      BatchNorm2d-23          [-1, 144, 61, 61]             288\n",
      "            ReLU6-24          [-1, 144, 61, 61]               0\n",
      "           Conv2d-25          [-1, 144, 61, 61]           1,296\n",
      "      BatchNorm2d-26          [-1, 144, 61, 61]             288\n",
      "            ReLU6-27          [-1, 144, 61, 61]               0\n",
      "         Identity-28          [-1, 144, 61, 61]               0\n",
      "           Conv2d-29           [-1, 24, 61, 61]           3,456\n",
      "      BatchNorm2d-30           [-1, 24, 61, 61]              48\n",
      " InvertedResidual-31           [-1, 24, 61, 61]               0\n",
      "           Conv2d-32          [-1, 144, 61, 61]           3,456\n",
      "      BatchNorm2d-33          [-1, 144, 61, 61]             288\n",
      "            ReLU6-34          [-1, 144, 61, 61]               0\n",
      "           Conv2d-35          [-1, 144, 31, 31]           1,296\n",
      "      BatchNorm2d-36          [-1, 144, 31, 31]             288\n",
      "            ReLU6-37          [-1, 144, 31, 31]               0\n",
      "         Identity-38          [-1, 144, 31, 31]               0\n",
      "           Conv2d-39           [-1, 32, 31, 31]           4,608\n",
      "      BatchNorm2d-40           [-1, 32, 31, 31]              64\n",
      " InvertedResidual-41           [-1, 32, 31, 31]               0\n",
      "           Conv2d-42          [-1, 192, 31, 31]           6,144\n",
      "      BatchNorm2d-43          [-1, 192, 31, 31]             384\n",
      "            ReLU6-44          [-1, 192, 31, 31]               0\n",
      "           Conv2d-45          [-1, 192, 31, 31]           1,728\n",
      "      BatchNorm2d-46          [-1, 192, 31, 31]             384\n",
      "            ReLU6-47          [-1, 192, 31, 31]               0\n",
      "         Identity-48          [-1, 192, 31, 31]               0\n",
      "           Conv2d-49           [-1, 32, 31, 31]           6,144\n",
      "      BatchNorm2d-50           [-1, 32, 31, 31]              64\n",
      " InvertedResidual-51           [-1, 32, 31, 31]               0\n",
      "           Conv2d-52          [-1, 192, 31, 31]           6,144\n",
      "      BatchNorm2d-53          [-1, 192, 31, 31]             384\n",
      "            ReLU6-54          [-1, 192, 31, 31]               0\n",
      "           Conv2d-55          [-1, 192, 31, 31]           1,728\n",
      "      BatchNorm2d-56          [-1, 192, 31, 31]             384\n",
      "            ReLU6-57          [-1, 192, 31, 31]               0\n",
      "         Identity-58          [-1, 192, 31, 31]               0\n",
      "           Conv2d-59           [-1, 32, 31, 31]           6,144\n",
      "      BatchNorm2d-60           [-1, 32, 31, 31]              64\n",
      " InvertedResidual-61           [-1, 32, 31, 31]               0\n",
      "           Conv2d-62          [-1, 192, 31, 31]           6,144\n",
      "      BatchNorm2d-63          [-1, 192, 31, 31]             384\n",
      "            ReLU6-64          [-1, 192, 31, 31]               0\n",
      "           Conv2d-65          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-66          [-1, 192, 16, 16]             384\n",
      "            ReLU6-67          [-1, 192, 16, 16]               0\n",
      "         Identity-68          [-1, 192, 16, 16]               0\n",
      "           Conv2d-69           [-1, 64, 16, 16]          12,288\n",
      "      BatchNorm2d-70           [-1, 64, 16, 16]             128\n",
      " InvertedResidual-71           [-1, 64, 16, 16]               0\n",
      "           Conv2d-72          [-1, 384, 16, 16]          24,576\n",
      "      BatchNorm2d-73          [-1, 384, 16, 16]             768\n",
      "            ReLU6-74          [-1, 384, 16, 16]               0\n",
      "           Conv2d-75          [-1, 384, 16, 16]           3,456\n",
      "      BatchNorm2d-76          [-1, 384, 16, 16]             768\n",
      "            ReLU6-77          [-1, 384, 16, 16]               0\n",
      "         Identity-78          [-1, 384, 16, 16]               0\n",
      "           Conv2d-79           [-1, 64, 16, 16]          24,576\n",
      "      BatchNorm2d-80           [-1, 64, 16, 16]             128\n",
      " InvertedResidual-81           [-1, 64, 16, 16]               0\n",
      "           Conv2d-82          [-1, 384, 16, 16]          24,576\n",
      "      BatchNorm2d-83          [-1, 384, 16, 16]             768\n",
      "            ReLU6-84          [-1, 384, 16, 16]               0\n",
      "           Conv2d-85          [-1, 384, 16, 16]           3,456\n",
      "      BatchNorm2d-86          [-1, 384, 16, 16]             768\n",
      "            ReLU6-87          [-1, 384, 16, 16]               0\n",
      "         Identity-88          [-1, 384, 16, 16]               0\n",
      "           Conv2d-89           [-1, 64, 16, 16]          24,576\n",
      "      BatchNorm2d-90           [-1, 64, 16, 16]             128\n",
      " InvertedResidual-91           [-1, 64, 16, 16]               0\n",
      "           Conv2d-92          [-1, 384, 16, 16]          24,576\n",
      "      BatchNorm2d-93          [-1, 384, 16, 16]             768\n",
      "            ReLU6-94          [-1, 384, 16, 16]               0\n",
      "           Conv2d-95          [-1, 384, 16, 16]           3,456\n",
      "      BatchNorm2d-96          [-1, 384, 16, 16]             768\n",
      "            ReLU6-97          [-1, 384, 16, 16]               0\n",
      "         Identity-98          [-1, 384, 16, 16]               0\n",
      "           Conv2d-99           [-1, 64, 16, 16]          24,576\n",
      "     BatchNorm2d-100           [-1, 64, 16, 16]             128\n",
      "InvertedResidual-101           [-1, 64, 16, 16]               0\n",
      "          Conv2d-102          [-1, 384, 16, 16]          24,576\n",
      "     BatchNorm2d-103          [-1, 384, 16, 16]             768\n",
      "           ReLU6-104          [-1, 384, 16, 16]               0\n",
      "          Conv2d-105          [-1, 384, 16, 16]           3,456\n",
      "     BatchNorm2d-106          [-1, 384, 16, 16]             768\n",
      "           ReLU6-107          [-1, 384, 16, 16]               0\n",
      "        Identity-108          [-1, 384, 16, 16]               0\n",
      "          Conv2d-109           [-1, 96, 16, 16]          36,864\n",
      "     BatchNorm2d-110           [-1, 96, 16, 16]             192\n",
      "InvertedResidual-111           [-1, 96, 16, 16]               0\n",
      "          Conv2d-112          [-1, 576, 16, 16]          55,296\n",
      "     BatchNorm2d-113          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-114          [-1, 576, 16, 16]               0\n",
      "          Conv2d-115          [-1, 576, 16, 16]           5,184\n",
      "     BatchNorm2d-116          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-117          [-1, 576, 16, 16]               0\n",
      "        Identity-118          [-1, 576, 16, 16]               0\n",
      "          Conv2d-119           [-1, 96, 16, 16]          55,296\n",
      "     BatchNorm2d-120           [-1, 96, 16, 16]             192\n",
      "InvertedResidual-121           [-1, 96, 16, 16]               0\n",
      "          Conv2d-122          [-1, 576, 16, 16]          55,296\n",
      "     BatchNorm2d-123          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-124          [-1, 576, 16, 16]               0\n",
      "          Conv2d-125          [-1, 576, 16, 16]           5,184\n",
      "     BatchNorm2d-126          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-127          [-1, 576, 16, 16]               0\n",
      "        Identity-128          [-1, 576, 16, 16]               0\n",
      "          Conv2d-129           [-1, 96, 16, 16]          55,296\n",
      "     BatchNorm2d-130           [-1, 96, 16, 16]             192\n",
      "InvertedResidual-131           [-1, 96, 16, 16]               0\n",
      "          Conv2d-132          [-1, 576, 16, 16]          55,296\n",
      "     BatchNorm2d-133          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-134          [-1, 576, 16, 16]               0\n",
      "          Conv2d-135            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-136            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-137            [-1, 576, 8, 8]               0\n",
      "        Identity-138            [-1, 576, 8, 8]               0\n",
      "          Conv2d-139            [-1, 160, 8, 8]          92,160\n",
      "     BatchNorm2d-140            [-1, 160, 8, 8]             320\n",
      "InvertedResidual-141            [-1, 160, 8, 8]               0\n",
      "          Conv2d-142            [-1, 960, 8, 8]         153,600\n",
      "     BatchNorm2d-143            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-144            [-1, 960, 8, 8]               0\n",
      "          Conv2d-145            [-1, 960, 8, 8]           8,640\n",
      "     BatchNorm2d-146            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-147            [-1, 960, 8, 8]               0\n",
      "        Identity-148            [-1, 960, 8, 8]               0\n",
      "          Conv2d-149            [-1, 160, 8, 8]         153,600\n",
      "     BatchNorm2d-150            [-1, 160, 8, 8]             320\n",
      "InvertedResidual-151            [-1, 160, 8, 8]               0\n",
      "          Conv2d-152            [-1, 960, 8, 8]         153,600\n",
      "     BatchNorm2d-153            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-154            [-1, 960, 8, 8]               0\n",
      "          Conv2d-155            [-1, 960, 8, 8]           8,640\n",
      "     BatchNorm2d-156            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-157            [-1, 960, 8, 8]               0\n",
      "        Identity-158            [-1, 960, 8, 8]               0\n",
      "          Conv2d-159            [-1, 160, 8, 8]         153,600\n",
      "     BatchNorm2d-160            [-1, 160, 8, 8]             320\n",
      "InvertedResidual-161            [-1, 160, 8, 8]               0\n",
      "          Conv2d-162            [-1, 960, 8, 8]         153,600\n",
      "     BatchNorm2d-163            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-164            [-1, 960, 8, 8]               0\n",
      "          Conv2d-165            [-1, 960, 8, 8]           8,640\n",
      "     BatchNorm2d-166            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-167            [-1, 960, 8, 8]               0\n",
      "        Identity-168            [-1, 960, 8, 8]               0\n",
      "          Conv2d-169            [-1, 320, 8, 8]         307,200\n",
      "     BatchNorm2d-170            [-1, 320, 8, 8]             640\n",
      "InvertedResidual-171            [-1, 320, 8, 8]               0\n",
      "          Conv2d-172           [-1, 1280, 8, 8]         409,600\n",
      "     BatchNorm2d-173           [-1, 1280, 8, 8]           2,560\n",
      "           ReLU6-174           [-1, 1280, 8, 8]               0\n",
      "AdaptiveAvgPool2d-175           [-1, 1280, 1, 1]               0\n",
      "         Flatten-176                 [-1, 1280]               0\n",
      "SelectAdaptivePool2d-177                 [-1, 1280]               0\n",
      "          Linear-178                 [-1, 1000]       1,281,000\n",
      "================================================================\n",
      "Total params: 3,504,872\n",
      "Trainable params: 3,504,872\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.68\n",
      "Forward/backward pass size (MB): 210.41\n",
      "Params size (MB): 13.37\n",
      "Estimated Total Size (MB): 224.46\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 122, 122]             432\n",
      "       BatchNorm2d-2         [-1, 16, 122, 122]              32\n",
      "         Hardswish-3         [-1, 16, 122, 122]               0\n",
      "            Conv2d-4         [-1, 16, 122, 122]             144\n",
      "       BatchNorm2d-5         [-1, 16, 122, 122]              32\n",
      "              ReLU-6         [-1, 16, 122, 122]               0\n",
      "          Identity-7         [-1, 16, 122, 122]               0\n",
      "            Conv2d-8         [-1, 16, 122, 122]             256\n",
      "       BatchNorm2d-9         [-1, 16, 122, 122]              32\n",
      "         Identity-10         [-1, 16, 122, 122]               0\n",
      "DepthwiseSeparableConv-11         [-1, 16, 122, 122]               0\n",
      "           Conv2d-12         [-1, 64, 122, 122]           1,024\n",
      "      BatchNorm2d-13         [-1, 64, 122, 122]             128\n",
      "             ReLU-14         [-1, 64, 122, 122]               0\n",
      "           Conv2d-15           [-1, 64, 61, 61]             576\n",
      "      BatchNorm2d-16           [-1, 64, 61, 61]             128\n",
      "             ReLU-17           [-1, 64, 61, 61]               0\n",
      "         Identity-18           [-1, 64, 61, 61]               0\n",
      "           Conv2d-19           [-1, 24, 61, 61]           1,536\n",
      "      BatchNorm2d-20           [-1, 24, 61, 61]              48\n",
      " InvertedResidual-21           [-1, 24, 61, 61]               0\n",
      "           Conv2d-22           [-1, 72, 61, 61]           1,728\n",
      "      BatchNorm2d-23           [-1, 72, 61, 61]             144\n",
      "             ReLU-24           [-1, 72, 61, 61]               0\n",
      "           Conv2d-25           [-1, 72, 61, 61]             648\n",
      "      BatchNorm2d-26           [-1, 72, 61, 61]             144\n",
      "             ReLU-27           [-1, 72, 61, 61]               0\n",
      "         Identity-28           [-1, 72, 61, 61]               0\n",
      "           Conv2d-29           [-1, 24, 61, 61]           1,728\n",
      "      BatchNorm2d-30           [-1, 24, 61, 61]              48\n",
      " InvertedResidual-31           [-1, 24, 61, 61]               0\n",
      "           Conv2d-32           [-1, 72, 61, 61]           1,728\n",
      "      BatchNorm2d-33           [-1, 72, 61, 61]             144\n",
      "             ReLU-34           [-1, 72, 61, 61]               0\n",
      "           Conv2d-35           [-1, 72, 31, 31]           1,800\n",
      "      BatchNorm2d-36           [-1, 72, 31, 31]             144\n",
      "             ReLU-37           [-1, 72, 31, 31]               0\n",
      "           Conv2d-38             [-1, 24, 1, 1]           1,752\n",
      "             ReLU-39             [-1, 24, 1, 1]               0\n",
      "           Conv2d-40             [-1, 72, 1, 1]           1,800\n",
      "      Hardsigmoid-41             [-1, 72, 1, 1]               0\n",
      "    SqueezeExcite-42           [-1, 72, 31, 31]               0\n",
      "           Conv2d-43           [-1, 40, 31, 31]           2,880\n",
      "      BatchNorm2d-44           [-1, 40, 31, 31]              80\n",
      " InvertedResidual-45           [-1, 40, 31, 31]               0\n",
      "           Conv2d-46          [-1, 120, 31, 31]           4,800\n",
      "      BatchNorm2d-47          [-1, 120, 31, 31]             240\n",
      "             ReLU-48          [-1, 120, 31, 31]               0\n",
      "           Conv2d-49          [-1, 120, 31, 31]           3,000\n",
      "      BatchNorm2d-50          [-1, 120, 31, 31]             240\n",
      "             ReLU-51          [-1, 120, 31, 31]               0\n",
      "           Conv2d-52             [-1, 32, 1, 1]           3,872\n",
      "             ReLU-53             [-1, 32, 1, 1]               0\n",
      "           Conv2d-54            [-1, 120, 1, 1]           3,960\n",
      "      Hardsigmoid-55            [-1, 120, 1, 1]               0\n",
      "    SqueezeExcite-56          [-1, 120, 31, 31]               0\n",
      "           Conv2d-57           [-1, 40, 31, 31]           4,800\n",
      "      BatchNorm2d-58           [-1, 40, 31, 31]              80\n",
      " InvertedResidual-59           [-1, 40, 31, 31]               0\n",
      "           Conv2d-60          [-1, 120, 31, 31]           4,800\n",
      "      BatchNorm2d-61          [-1, 120, 31, 31]             240\n",
      "             ReLU-62          [-1, 120, 31, 31]               0\n",
      "           Conv2d-63          [-1, 120, 31, 31]           3,000\n",
      "      BatchNorm2d-64          [-1, 120, 31, 31]             240\n",
      "             ReLU-65          [-1, 120, 31, 31]               0\n",
      "           Conv2d-66             [-1, 32, 1, 1]           3,872\n",
      "             ReLU-67             [-1, 32, 1, 1]               0\n",
      "           Conv2d-68            [-1, 120, 1, 1]           3,960\n",
      "      Hardsigmoid-69            [-1, 120, 1, 1]               0\n",
      "    SqueezeExcite-70          [-1, 120, 31, 31]               0\n",
      "           Conv2d-71           [-1, 40, 31, 31]           4,800\n",
      "      BatchNorm2d-72           [-1, 40, 31, 31]              80\n",
      " InvertedResidual-73           [-1, 40, 31, 31]               0\n",
      "           Conv2d-74          [-1, 240, 31, 31]           9,600\n",
      "      BatchNorm2d-75          [-1, 240, 31, 31]             480\n",
      "        Hardswish-76          [-1, 240, 31, 31]               0\n",
      "           Conv2d-77          [-1, 240, 16, 16]           2,160\n",
      "      BatchNorm2d-78          [-1, 240, 16, 16]             480\n",
      "        Hardswish-79          [-1, 240, 16, 16]               0\n",
      "         Identity-80          [-1, 240, 16, 16]               0\n",
      "           Conv2d-81           [-1, 80, 16, 16]          19,200\n",
      "      BatchNorm2d-82           [-1, 80, 16, 16]             160\n",
      " InvertedResidual-83           [-1, 80, 16, 16]               0\n",
      "           Conv2d-84          [-1, 200, 16, 16]          16,000\n",
      "      BatchNorm2d-85          [-1, 200, 16, 16]             400\n",
      "        Hardswish-86          [-1, 200, 16, 16]               0\n",
      "           Conv2d-87          [-1, 200, 16, 16]           1,800\n",
      "      BatchNorm2d-88          [-1, 200, 16, 16]             400\n",
      "        Hardswish-89          [-1, 200, 16, 16]               0\n",
      "         Identity-90          [-1, 200, 16, 16]               0\n",
      "           Conv2d-91           [-1, 80, 16, 16]          16,000\n",
      "      BatchNorm2d-92           [-1, 80, 16, 16]             160\n",
      " InvertedResidual-93           [-1, 80, 16, 16]               0\n",
      "           Conv2d-94          [-1, 184, 16, 16]          14,720\n",
      "      BatchNorm2d-95          [-1, 184, 16, 16]             368\n",
      "        Hardswish-96          [-1, 184, 16, 16]               0\n",
      "           Conv2d-97          [-1, 184, 16, 16]           1,656\n",
      "      BatchNorm2d-98          [-1, 184, 16, 16]             368\n",
      "        Hardswish-99          [-1, 184, 16, 16]               0\n",
      "        Identity-100          [-1, 184, 16, 16]               0\n",
      "          Conv2d-101           [-1, 80, 16, 16]          14,720\n",
      "     BatchNorm2d-102           [-1, 80, 16, 16]             160\n",
      "InvertedResidual-103           [-1, 80, 16, 16]               0\n",
      "          Conv2d-104          [-1, 184, 16, 16]          14,720\n",
      "     BatchNorm2d-105          [-1, 184, 16, 16]             368\n",
      "       Hardswish-106          [-1, 184, 16, 16]               0\n",
      "          Conv2d-107          [-1, 184, 16, 16]           1,656\n",
      "     BatchNorm2d-108          [-1, 184, 16, 16]             368\n",
      "       Hardswish-109          [-1, 184, 16, 16]               0\n",
      "        Identity-110          [-1, 184, 16, 16]               0\n",
      "          Conv2d-111           [-1, 80, 16, 16]          14,720\n",
      "     BatchNorm2d-112           [-1, 80, 16, 16]             160\n",
      "InvertedResidual-113           [-1, 80, 16, 16]               0\n",
      "          Conv2d-114          [-1, 480, 16, 16]          38,400\n",
      "     BatchNorm2d-115          [-1, 480, 16, 16]             960\n",
      "       Hardswish-116          [-1, 480, 16, 16]               0\n",
      "          Conv2d-117          [-1, 480, 16, 16]           4,320\n",
      "     BatchNorm2d-118          [-1, 480, 16, 16]             960\n",
      "       Hardswish-119          [-1, 480, 16, 16]               0\n",
      "          Conv2d-120            [-1, 120, 1, 1]          57,720\n",
      "            ReLU-121            [-1, 120, 1, 1]               0\n",
      "          Conv2d-122            [-1, 480, 1, 1]          58,080\n",
      "     Hardsigmoid-123            [-1, 480, 1, 1]               0\n",
      "   SqueezeExcite-124          [-1, 480, 16, 16]               0\n",
      "          Conv2d-125          [-1, 112, 16, 16]          53,760\n",
      "     BatchNorm2d-126          [-1, 112, 16, 16]             224\n",
      "InvertedResidual-127          [-1, 112, 16, 16]               0\n",
      "          Conv2d-128          [-1, 672, 16, 16]          75,264\n",
      "     BatchNorm2d-129          [-1, 672, 16, 16]           1,344\n",
      "       Hardswish-130          [-1, 672, 16, 16]               0\n",
      "          Conv2d-131          [-1, 672, 16, 16]           6,048\n",
      "     BatchNorm2d-132          [-1, 672, 16, 16]           1,344\n",
      "       Hardswish-133          [-1, 672, 16, 16]               0\n",
      "          Conv2d-134            [-1, 168, 1, 1]         113,064\n",
      "            ReLU-135            [-1, 168, 1, 1]               0\n",
      "          Conv2d-136            [-1, 672, 1, 1]         113,568\n",
      "     Hardsigmoid-137            [-1, 672, 1, 1]               0\n",
      "   SqueezeExcite-138          [-1, 672, 16, 16]               0\n",
      "          Conv2d-139          [-1, 112, 16, 16]          75,264\n",
      "     BatchNorm2d-140          [-1, 112, 16, 16]             224\n",
      "InvertedResidual-141          [-1, 112, 16, 16]               0\n",
      "          Conv2d-142          [-1, 672, 16, 16]          75,264\n",
      "     BatchNorm2d-143          [-1, 672, 16, 16]           1,344\n",
      "       Hardswish-144          [-1, 672, 16, 16]               0\n",
      "          Conv2d-145            [-1, 672, 8, 8]          16,800\n",
      "     BatchNorm2d-146            [-1, 672, 8, 8]           1,344\n",
      "       Hardswish-147            [-1, 672, 8, 8]               0\n",
      "          Conv2d-148            [-1, 168, 1, 1]         113,064\n",
      "            ReLU-149            [-1, 168, 1, 1]               0\n",
      "          Conv2d-150            [-1, 672, 1, 1]         113,568\n",
      "     Hardsigmoid-151            [-1, 672, 1, 1]               0\n",
      "   SqueezeExcite-152            [-1, 672, 8, 8]               0\n",
      "          Conv2d-153            [-1, 160, 8, 8]         107,520\n",
      "     BatchNorm2d-154            [-1, 160, 8, 8]             320\n",
      "InvertedResidual-155            [-1, 160, 8, 8]               0\n",
      "          Conv2d-156            [-1, 960, 8, 8]         153,600\n",
      "     BatchNorm2d-157            [-1, 960, 8, 8]           1,920\n",
      "       Hardswish-158            [-1, 960, 8, 8]               0\n",
      "          Conv2d-159            [-1, 960, 8, 8]          24,000\n",
      "     BatchNorm2d-160            [-1, 960, 8, 8]           1,920\n",
      "       Hardswish-161            [-1, 960, 8, 8]               0\n",
      "          Conv2d-162            [-1, 240, 1, 1]         230,640\n",
      "            ReLU-163            [-1, 240, 1, 1]               0\n",
      "          Conv2d-164            [-1, 960, 1, 1]         231,360\n",
      "     Hardsigmoid-165            [-1, 960, 1, 1]               0\n",
      "   SqueezeExcite-166            [-1, 960, 8, 8]               0\n",
      "          Conv2d-167            [-1, 160, 8, 8]         153,600\n",
      "     BatchNorm2d-168            [-1, 160, 8, 8]             320\n",
      "InvertedResidual-169            [-1, 160, 8, 8]               0\n",
      "          Conv2d-170            [-1, 960, 8, 8]         153,600\n",
      "     BatchNorm2d-171            [-1, 960, 8, 8]           1,920\n",
      "       Hardswish-172            [-1, 960, 8, 8]               0\n",
      "          Conv2d-173            [-1, 960, 8, 8]          24,000\n",
      "     BatchNorm2d-174            [-1, 960, 8, 8]           1,920\n",
      "       Hardswish-175            [-1, 960, 8, 8]               0\n",
      "          Conv2d-176            [-1, 240, 1, 1]         230,640\n",
      "            ReLU-177            [-1, 240, 1, 1]               0\n",
      "          Conv2d-178            [-1, 960, 1, 1]         231,360\n",
      "     Hardsigmoid-179            [-1, 960, 1, 1]               0\n",
      "   SqueezeExcite-180            [-1, 960, 8, 8]               0\n",
      "          Conv2d-181            [-1, 160, 8, 8]         153,600\n",
      "     BatchNorm2d-182            [-1, 160, 8, 8]             320\n",
      "InvertedResidual-183            [-1, 160, 8, 8]               0\n",
      "          Conv2d-184            [-1, 960, 8, 8]         153,600\n",
      "     BatchNorm2d-185            [-1, 960, 8, 8]           1,920\n",
      "       Hardswish-186            [-1, 960, 8, 8]               0\n",
      "       ConvBnAct-187            [-1, 960, 8, 8]               0\n",
      "AdaptiveAvgPool2d-188            [-1, 960, 1, 1]               0\n",
      "        Identity-189            [-1, 960, 1, 1]               0\n",
      "SelectAdaptivePool2d-190            [-1, 960, 1, 1]               0\n",
      "          Conv2d-191           [-1, 1280, 1, 1]       1,230,080\n",
      "       Hardswish-192           [-1, 1280, 1, 1]               0\n",
      "         Flatten-193                 [-1, 1280]               0\n",
      "          Linear-194                 [-1, 1000]       1,281,000\n",
      "================================================================\n",
      "Total params: 5,483,032\n",
      "Trainable params: 5,483,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.68\n",
      "Forward/backward pass size (MB): 139.04\n",
      "Params size (MB): 20.92\n",
      "Estimated Total Size (MB): 160.63\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mv3 = timm.create_model('mobilenetv3_large_100').cuda()\n",
    "summary(mv3, input_size=(3,244,244))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNet(\n",
      "  (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): ReLU6(inplace=True)\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU6(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU6(inplace=True)\n",
      "        (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU6(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU6(inplace=True)\n",
      "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU6(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU6(inplace=True)\n",
      "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU6(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU6(inplace=True)\n",
      "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU6(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU6(inplace=True)\n",
      "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU6(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU6(inplace=True)\n",
      "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU6(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU6(inplace=True)\n",
      "        (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU6(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU6(inplace=True)\n",
      "        (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU6(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU6(inplace=True)\n",
      "        (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU6(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU6(inplace=True)\n",
      "        (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU6(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU6(inplace=True)\n",
      "        (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU6(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU6(inplace=True)\n",
      "        (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU6(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU6(inplace=True)\n",
      "        (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "        (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU6(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU6(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU6(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU6(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU6(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU6(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU6(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act2): ReLU6(inplace=True)\n",
      "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "  (classifier): Linear(in_features=1280, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mv2 = timm.create_model('mobilenetv2_100')\n",
    "print(mv2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "31b2b117d925460da48098fd0fb28d20"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8563da13ea254239b4ff99b58a073030"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c6fe56484824eb0bcacc0a15c6b1385"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "323a12cdb97d4c219bf73eefc2db2bb3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\torch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:335: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed).view(length, num_rows, num_cols)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "[  1/100] train_loss: 0.82333 valid_loss: 0.29947\n",
      "Validation loss decreased (inf --> 0.299474).  Saving model ...\n",
      "[  2/100] train_loss: 0.36800 valid_loss: 0.21973\n",
      "Validation loss decreased (0.299474 --> 0.219734).  Saving model ...\n",
      "[  3/100] train_loss: 0.29981 valid_loss: 0.18481\n",
      "Validation loss decreased (0.219734 --> 0.184809).  Saving model ...\n",
      "[  4/100] train_loss: 0.25914 valid_loss: 0.16143\n",
      "Validation loss decreased (0.184809 --> 0.161426).  Saving model ...\n",
      "[  5/100] train_loss: 0.23563 valid_loss: 0.14466\n",
      "Validation loss decreased (0.161426 --> 0.144659).  Saving model ...\n",
      "[  6/100] train_loss: 0.21477 valid_loss: 0.13740\n",
      "Validation loss decreased (0.144659 --> 0.137403).  Saving model ...\n",
      "[  7/100] train_loss: 0.19750 valid_loss: 0.13469\n",
      "Validation loss decreased (0.137403 --> 0.134688).  Saving model ...\n",
      "[  8/100] train_loss: 0.18343 valid_loss: 0.12281\n",
      "Validation loss decreased (0.134688 --> 0.122814).  Saving model ...\n",
      "[  9/100] train_loss: 0.17432 valid_loss: 0.11547\n",
      "Validation loss decreased (0.122814 --> 0.115471).  Saving model ...\n",
      "[ 10/100] train_loss: 0.17058 valid_loss: 0.11003\n",
      "Validation loss decreased (0.115471 --> 0.110032).  Saving model ...\n",
      "[ 11/100] train_loss: 0.15810 valid_loss: 0.10612\n",
      "Validation loss decreased (0.110032 --> 0.106122).  Saving model ...\n",
      "[ 12/100] train_loss: 0.15315 valid_loss: 0.10582\n",
      "Validation loss decreased (0.106122 --> 0.105817).  Saving model ...\n",
      "[ 13/100] train_loss: 0.14781 valid_loss: 0.09897\n",
      "Validation loss decreased (0.105817 --> 0.098966).  Saving model ...\n",
      "[ 14/100] train_loss: 0.14538 valid_loss: 0.10105\n",
      "EarlyStopping counter: 1 out of 20\n",
      "[ 15/100] train_loss: 0.14245 valid_loss: 0.09876\n",
      "Validation loss decreased (0.098966 --> 0.098756).  Saving model ...\n",
      "[ 16/100] train_loss: 0.13708 valid_loss: 0.09802\n",
      "Validation loss decreased (0.098756 --> 0.098016).  Saving model ...\n",
      "[ 17/100] train_loss: 0.13421 valid_loss: 0.09599\n",
      "Validation loss decreased (0.098016 --> 0.095988).  Saving model ...\n",
      "[ 18/100] train_loss: 0.12893 valid_loss: 0.09588\n",
      "Validation loss decreased (0.095988 --> 0.095883).  Saving model ...\n",
      "[ 19/100] train_loss: 0.12463 valid_loss: 0.09604\n",
      "EarlyStopping counter: 1 out of 20\n",
      "[ 20/100] train_loss: 0.12444 valid_loss: 0.09299\n",
      "Validation loss decreased (0.095883 --> 0.092995).  Saving model ...\n",
      "[ 21/100] train_loss: 0.12077 valid_loss: 0.09076\n",
      "Validation loss decreased (0.092995 --> 0.090761).  Saving model ...\n",
      "[ 22/100] train_loss: 0.11628 valid_loss: 0.09227\n",
      "EarlyStopping counter: 1 out of 20\n",
      "[ 23/100] train_loss: 0.11624 valid_loss: 0.09231\n",
      "EarlyStopping counter: 2 out of 20\n",
      "[ 24/100] train_loss: 0.11586 valid_loss: 0.09055\n",
      "Validation loss decreased (0.090761 --> 0.090547).  Saving model ...\n",
      "[ 25/100] train_loss: 0.11064 valid_loss: 0.08918\n",
      "Validation loss decreased (0.090547 --> 0.089182).  Saving model ...\n",
      "[ 26/100] train_loss: 0.10822 valid_loss: 0.08855\n",
      "Validation loss decreased (0.089182 --> 0.088546).  Saving model ...\n",
      "[ 27/100] train_loss: 0.10864 valid_loss: 0.08999\n",
      "EarlyStopping counter: 1 out of 20\n",
      "[ 28/100] train_loss: 0.10641 valid_loss: 0.08891\n",
      "EarlyStopping counter: 2 out of 20\n",
      "[ 29/100] train_loss: 0.10285 valid_loss: 0.09042\n",
      "EarlyStopping counter: 3 out of 20\n",
      "[ 30/100] train_loss: 0.10548 valid_loss: 0.08576\n",
      "Validation loss decreased (0.088546 --> 0.085764).  Saving model ...\n",
      "[ 31/100] train_loss: 0.10135 valid_loss: 0.09017\n",
      "EarlyStopping counter: 1 out of 20\n",
      "[ 32/100] train_loss: 0.10028 valid_loss: 0.08757\n",
      "EarlyStopping counter: 2 out of 20\n",
      "[ 33/100] train_loss: 0.09930 valid_loss: 0.09011\n",
      "EarlyStopping counter: 3 out of 20\n",
      "[ 34/100] train_loss: 0.09875 valid_loss: 0.08684\n",
      "EarlyStopping counter: 4 out of 20\n",
      "[ 35/100] train_loss: 0.09639 valid_loss: 0.08770\n",
      "EarlyStopping counter: 5 out of 20\n",
      "[ 36/100] train_loss: 0.09537 valid_loss: 0.08953\n",
      "EarlyStopping counter: 6 out of 20\n",
      "[ 37/100] train_loss: 0.09233 valid_loss: 0.09126\n",
      "EarlyStopping counter: 7 out of 20\n",
      "[ 38/100] train_loss: 0.09496 valid_loss: 0.08873\n",
      "EarlyStopping counter: 8 out of 20\n",
      "[ 39/100] train_loss: 0.09071 valid_loss: 0.08975\n",
      "EarlyStopping counter: 9 out of 20\n",
      "[ 40/100] train_loss: 0.08893 valid_loss: 0.09101\n",
      "EarlyStopping counter: 10 out of 20\n",
      "[ 41/100] train_loss: 0.08903 valid_loss: 0.09039\n",
      "EarlyStopping counter: 11 out of 20\n",
      "[ 42/100] train_loss: 0.09163 valid_loss: 0.09264\n",
      "EarlyStopping counter: 12 out of 20\n",
      "[ 43/100] train_loss: 0.08807 valid_loss: 0.08959\n",
      "EarlyStopping counter: 13 out of 20\n",
      "[ 44/100] train_loss: 0.09179 valid_loss: 0.08726\n",
      "EarlyStopping counter: 14 out of 20\n",
      "[ 45/100] train_loss: 0.08894 valid_loss: 0.09202\n",
      "EarlyStopping counter: 15 out of 20\n",
      "[ 46/100] train_loss: 0.08940 valid_loss: 0.08655\n",
      "EarlyStopping counter: 16 out of 20\n",
      "[ 47/100] train_loss: 0.08817 valid_loss: 0.08352\n",
      "Validation loss decreased (0.085764 --> 0.083516).  Saving model ...\n",
      "[ 48/100] train_loss: 0.08431 valid_loss: 0.08678\n",
      "EarlyStopping counter: 1 out of 20\n",
      "[ 49/100] train_loss: 0.08263 valid_loss: 0.08926\n",
      "EarlyStopping counter: 2 out of 20\n",
      "[ 50/100] train_loss: 0.08337 valid_loss: 0.09035\n",
      "EarlyStopping counter: 3 out of 20\n",
      "[ 51/100] train_loss: 0.07926 valid_loss: 0.08603\n",
      "EarlyStopping counter: 4 out of 20\n",
      "[ 52/100] train_loss: 0.08226 valid_loss: 0.08758\n",
      "EarlyStopping counter: 5 out of 20\n",
      "[ 53/100] train_loss: 0.08132 valid_loss: 0.09059\n",
      "EarlyStopping counter: 6 out of 20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_22540/4176075828.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[0mpatience\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m20\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m \u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalid_loss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpatience\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_epochs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_22540/1080229626.py\u001B[0m in \u001B[0;36mtrain_model\u001B[1;34m(model, batch_size, patience, n_epochs)\u001B[0m\n\u001B[0;32m     38\u001B[0m         \u001B[1;31m######################\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     39\u001B[0m         \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0meval\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m# prep model for evaluation\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 40\u001B[1;33m         \u001B[1;32mfor\u001B[0m \u001B[0mdata\u001B[0m \u001B[1;33m,\u001B[0m \u001B[0mtarget\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mvalid_loader\u001B[0m \u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     41\u001B[0m             \u001B[1;31m# forward pass:       \u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     42\u001B[0m             \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    519\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sampler_iter\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    520\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 521\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    522\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    523\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[1;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    559\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    560\u001B[0m         \u001B[0mindex\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# may raise StopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 561\u001B[1;33m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# may raise StopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    562\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    563\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     42\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 44\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     45\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     42\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 44\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     45\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\torch\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     94\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 95\u001B[1;33m             \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     96\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     97\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtarget_transform\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\torch\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, pic)\u001B[0m\n\u001B[0;32m     89\u001B[0m             \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mConverted\u001B[0m \u001B[0mimage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     90\u001B[0m         \"\"\"\n\u001B[1;32m---> 91\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_tensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpic\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     92\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     93\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__repr__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\torch\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001B[0m in \u001B[0;36mto_tensor\u001B[1;34m(pic)\u001B[0m\n\u001B[0;32m     77\u001B[0m         \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m255\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_numpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpic\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0muint8\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     78\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 79\u001B[1;33m         \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mByteTensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mByteStorage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_buffer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpic\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtobytes\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     80\u001B[0m     \u001B[1;31m# PIL image mode: L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     81\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mpic\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'YCbCr'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\torch\\lib\\site-packages\\PIL\\Image.py\u001B[0m in \u001B[0;36mtobytes\u001B[1;34m(self, encoder_name, *args)\u001B[0m\n\u001B[0;32m    718\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrombytes\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    719\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 720\u001B[1;33m     \u001B[1;32mdef\u001B[0m \u001B[0mtobytes\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mencoder_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"raw\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    721\u001B[0m         \"\"\"\n\u001B[0;32m    722\u001B[0m         \u001B[0mReturn\u001B[0m \u001B[0mimage\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0ma\u001B[0m \u001B[0mbytes\u001B[0m \u001B[0mobject\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%"
    }
   }
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}